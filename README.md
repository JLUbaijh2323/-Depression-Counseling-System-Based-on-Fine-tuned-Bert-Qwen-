
# 基于Bert-Qwen的抑郁心理疏导系统  
[![Python Version](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-Transformers-orange.svg)](https://huggingface.co/)


## 🌐 项目简介  
本项目是一个结合自然语言处理（NLP）技术的智能化抑郁心理疏导系统，旨在通过文本分析识别抑郁相关症状及隐喻表达，并生成专业的心理疏导建议。系统集成了**多标签分类模型**（DistilBert）和**对话生成模型**（Qwen-2.5），支持命令行交互和Web界面，为心理服务提供高效的技术辅助工具。  

### 核心优势  
1. **多维度检测**：同时识别3类症状（情绪低落、睡眠障碍、自杀倾向）和3类隐喻（自然现象、机械故障、空间压迫），覆盖抑郁相关的典型心理特征。  
2. **结构化输出**：严格遵循`案例分析+回复建议`格式，支持首句建议提取，便于快速应用。  
3. **高效微调**：基于LoRA技术对Qwen模型进行轻量化微调，在保持性能的同时降低计算成本。  
4. **双模式交互**：提供命令行和Web界面两种使用方式，适配不同场景需求。  


## 🛠️ 技术架构  
### 1. 文本分类模块（DistilBert）  
#### 技术细节  
- **模型**：基于`Geotrend/distilbert-base-zh-cased`中文预训练模型，针对7类标签进行多标签分类。  
- **损失函数**：`BCEWithLogitsLoss`，自动计算类别权重平衡正负样本（如自杀倾向标签权重更高）。  
- **评估指标**：宏平均F1、各标签精确率/召回率，重点优化抑郁相关标签的检测精度。  
- **推理流程**：使用HuggingFace Pipeline进行文本分类，动态过滤置信度>0.5的标签。  

#### 标签体系  
| 标签类型       | 具体标签                | 说明                          |  
|----------------|-------------------------|-------------------------------|  
| **症状**       | S2（情绪低落）          | 0=无，1=有                     |  
|                | S3（睡眠障碍）          | 0=无，1=有                     |  
|                | S9（自杀倾向）          | 0=无，1=有                     |  
| **隐喻**       | 自然现象隐喻            | 0=无，1=有（如“人生像暴风雨”）|  
|                | 机械故障隐喻            | 0=无，1=有（如“心脏像生锈的齿轮”）|  
|                | 空间压迫隐喻            | 0=无，1=有（如“被困在狭小的盒子里”）|  
| **独立标签**   | 抑郁                    | 0=无，1=有（综合判断标识）      |  

### 2. 文本生成模块（Qwen-2.5 + LoRA）  
#### 技术细节  
- **基础模型**：`Qwen2.5-0.5B-Instruct`（中文对话模型，支持长上下文理解）。  
- **微调技术**：  
  - 使用`Peft`库实现LoRA微调，冻结基础模型参数，仅训练低秩适配器（Rank=8）。  
  - 训练数据：包含10万+条结构化样本（格式为`[症状][隐喻][抑郁] + 原始文本 → 案例分析+建议`）。  
  - 超参数：学习率`2e-5`，训练轮次15epoch，批次大小16，使用温度0.2控制生成稳定性。  
- **输出控制**：通过前缀提示严格约束生成格式，确保输出包含`案例分析`和`回复建议`两部分。  


## 🚀 核心功能详解  
### 1. 多标签文本检测  
#### 输入示例  
```text
最近总是失眠，感觉心里像压了一块石头，做什么都提不起劲，甚至想过一了百了。
```  

#### 检测流程  
1. 文本清洗：去除特殊符号，统一小写。  
2. 分类推理：输出置信度>0.5的标签列表（如`['LABEL_0', 'LABEL_1', 'LABEL_2']`）。  
3. 标签映射：根据`ID2TAG`字典转换为结构化数据（症状、隐喻、抑郁标识）。  

#### 输出结果  
```python
{
    "症状": {"S2": 1, "S3": 1, "S9": 1},
    "隐喻": [],
    "抑郁": 1
}
```  

### 2. 结构化输入构建  
将检测结果转换为模型训练时的标准输入格式，示例：  
```text
[症状:S2=1,S3=1,S9=1][抑郁] 最近总是失眠，感觉心里像压了一块石头，做什么都提不起劲，甚至想过一了百了。
```  

### 3. 智能回复生成  
#### 生成逻辑  
- 提示模板：强制要求输出`案例分析`和`回复建议`，格式严格对齐训练数据。  
- 示例输出：  
  ```text
  案例分析：患者存在情绪低落、睡眠障碍、自杀倾向的症状，且有抑郁倾向。  
  回复建议：立即联系专业心理医生进行干预，同时与家人朋友保持沟通，避免独处。  
  ```  
- 建议处理：自动提取回复建议的首句话，确保简洁实用。  


## 📦 安装指南  
### 环境准备  
1. **Python环境**：建议使用Python 3.8+，推荐通过虚拟环境管理：  
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   venv\Scripts\activate     # Windows
   ```  

2. **CUDA配置**（可选，GPU加速）：  
   - 安装CUDA 11.8+及对应CuDNN，确保`nvidia-smi`可正常识别显卡。  
   - 安装PyTorch GPU版本：  
     ```bash
     pip install torch==2.1.0+cu118 -f https://download.pytorch.org/whl/cu118/torch_stable.html
     ```  

### 依赖安装  
```bash
# 基础依赖
pip install flask pandas numpy python-dotenv

# 模型与NLP库
pip install transformers==4.35.2 sentencepiece==0.1.99 accelerate==0.25.0 datasets==2.14.4

# 微调与优化（必选，用于加载LoRA模型）
pip install peft==0.4.0
```  

### 模型下载  
1. **DistilBert分类模型**：从`main/distilbert_final_model`目录加载，或通过HuggingFace自动下载（需联网）。  
2. **Qwen基础模型**：  
   - 下载地址：[Qwen2.5-0.5B-Instruct](https://modelscope.cn/models/qwen/Qwen-2.5-0.5B-Instruct/summary)  
   - 解压后放置于`main/QwenQwen2.5-0.5B-Instruct/`目录。  
3. **LoRA微调权重**：从`main/Qwen2.5-0.5B-Instruct/lora/`目录加载，需包含`adapter_model.safetensors`文件。  


## 🎮 使用方法  
### 1. 命令行模式  
```bash
python main/main.py
```  
#### 交互流程  
1. 输入文本后按回车，系统将依次输出：  
   - 检测到的标签列表  
   - 结构化输入内容  
   - 案例分析与回复建议（带颜色标注）  

#### 示例输出  
```text
请输入文本: 最近晚上总是睡不着，感觉生活就像一台坏掉的机器，没有动力。

加载分类模型...
检测到标签: ['LABEL_1', 'LABEL_4']

结构化输入: [症状:S2=0,S3=1,S9=0][隐喻:机械故障隐喻]

加载Qwen模型...
生成结构化回复...

=== 案例分析 ===
案例分析：患者存在睡眠障碍的症状，且使用了机械故障隐喻的表达。

=== 回复建议 ===
回复建议：尝试制定规律的作息时间表，同时可以记录下每天的感受，分析“机器故障”背后的具体困扰。
```  

### 2. Web界面（Flask）  
```bash
python main/app.py
```  
#### 界面功能  
- **输入区**：支持多行文本输入，最大长度512字。  
- **分析按钮**：点击后调用后端API，返回结构化结果。  
- **结果展示**：  
  - 案例分析：蓝色区块，展示症状和隐喻的具体描述。  
  - 回复建议：绿色区块，仅显示首句建议，便于快速查看。  

#### 界面截图（文字描述）  
- 顶部标题：“基于Bert-Qwen的抑郁心理疏导系统”  
- 中央文本框：占据页面70%宽度，下方有“分析”按钮。  
- 结果区：两个卡片式区块，分别用蓝色和绿色高亮，内容左对齐显示。  


## 🔬 目录结构详解  
```
├── data/                # 数据存储
│   ├── output_dataset.json  # 生成的结构化输出示例（用于测试）
│   └── train.xls         # 标注好的训练数据集（包含文本、标签、建议）
├── distil_bert_train/   # DistilBert训练代码
│   ├── train.py          # 分类模型训练脚本（含数据预处理、自定义损失函数）
│   └── training_log.txt  # 训练日志（记录损失、指标、错误信息）
├── data_gene/           # 数据生成与标注
│   ├── data_generate/    # 数据增强脚本（如多样化建议生成）
│   │   ├── depression_gene_forbert.py  # 生成Bert训练数据
│   │   └── gene_forQwen.py            # 生成Qwen微调数据
│   └── datasets/         # 原始及中间数据集
│       ├── raw_data.csv  # 未标注的原始文本数据
│       └── labeled_data.csv # 人工标注或GLM-4辅助标注的数据
├── main/                # 主程序与模型文件
│   ├── distilbert_final_model/  # 分类模型最终权重
│   │   ├── model.safetensors  # 模型参数（FP16格式）
│   │   └── tokenizer.json     # 分词器配置
│   ├── Qwen2.5-0.5B-Instruct/  # Qwen基础模型与微调结果
│   │   ├── model.safetensors    # 原始模型参数
│   │   └── lora/               # LoRA微调权重（多个训练 checkpoint）
│   ├── app.py            # Web界面入口（Flask应用）
│   └── main.py           # 命令行主程序（核心逻辑封装）
├── docs/                # 文档目录（待扩展）
│   └── architecture.png  # 技术架构图（建议手动添加）
├── LICENSE              # 软件许可证（MIT协议）
└── README.md            # 项目说明文档
```  


## 🧠 微调Qwen模型（Llamafactory webGUI详细步骤）  
### 1. 数据预处理  
- **格式要求**：JSON数组，每个样本包含`input`（结构化输入）和`output`（案例分析+建议）：  
  ```json
  [
    {
      "input": "[症状:S2=1,S3=0,S9=0][隐喻:自然现象隐喻] 最近心情像阴天一样低落。",
      "output": "案例分析：患者存在情绪低落的症状，且使用了自然现象隐喻。\n回复建议：可以多到户外走走，感受阳光和自然的美好，帮助调节情绪。"
    }
  ]
  ```  
- **数据清洗**：确保无特殊符号，建议文本长度控制在100字内。  

### 2. 启动Llamafactory GUI  
1. 下载并安装[Llamafactory](https://llamafactory.com/)（需注册账号）。  
2. 打开“模型训练”模块，选择“LoRA微调”。  

### 3. 配置训练参数  
| 参数            | 建议值                  | 说明                          |  
|-----------------|-------------------------|-------------------------------|  
| 基础模型路径    | `main/QwenQwen2.5-0.5B-Instruct` | Qwen基础模型目录             |  
| 训练数据路径    | `data_gene/datasets/labeled_data.json` | 预处理后的JSON数据          |  
| 训练批次大小    | 8-16                    | 根据显卡显存调整（6GB显存建议8）|  
| 学习率          | 1e-4                    | LoRA专用学习率，避免过高导致过拟合|  
| LoRA秩（Rank）   | 8                       | 低秩矩阵分解维度，平衡效率与性能|  
| 训练轮次（Epoch）| 10-15                   | 建议通过验证集监控过拟合情况|  
| 权重保存间隔    | 每200步保存            | 避免频繁保存影响训练速度      |  

### 4. 训练监控与调优  
- **损失曲线**：确保训练损失逐步下降，验证损失在第8-10epoch后趋于稳定。  
- **生成测试**：每轮训练后使用`main.py`进行推理测试，检查建议的相关性和格式正确性。  
- **过拟合处理**：若验证损失上升，可增加`weight_decay`（如0.01）或降低学习率。  

### 5. 模型集成  
训练完成后，将生成的LoRA权重目录（如`checkpoint-180`）复制到`main/Qwen2.5-0.5B-Instruct/lora/`，系统将自动加载最新权重。  


## 🤝 贡献与反馈  
### 如何贡献  
1. **代码贡献**：  
   - Fork本仓库，创建功能分支（如`feature/improve-bert`）。  
   - 提交前运行代码检查：`pylint . --ignore=venv/`，修复所有警告。  
   - 附带单元测试（如新增功能的输入输出测试）。  
2. **文档贡献**：  
   - 补充技术细节、使用示例或常见问题解答。  
   - 在`docs/`目录添加架构图、流程图等可视化内容。  
3. **数据贡献**：  
   - 提供标注好的抑郁相关文本数据（遵循`train.xls`格式）。  
   - 优化建议模板库（`suggestion_templates`），增加多样化回复。  

### 反馈渠道  
- **GitHub Issues**：优先通过Issue报告Bug或提出需求。  
- **邮箱联系**：发送邮件至`baijh2323@example.com`（标题注明“抑郁疏导系统反馈”）。  


## 📄 许可证  
本项目采用**MIT许可证**，允许自由使用、修改和分发，但需在项目中保留原作者版权声明。 


## 🔮 未来计划  
1. **功能扩展**：  
   - 增加语音输入/输出支持（需集成ASR/TTS模块）。  
   - 实现用户历史记录管理，支持个性化建议生成。  
2. **模型优化**：  
   - 尝试全参数微调（Full Fine-Tuning）对比LoRA效果。  
   - 集成多模态输入（如图片中的隐喻识别）。  
3. **部署升级**：  
   - 支持Docker容器化部署，简化生产环境配置。  
   - 开发微信小程序版本，提升移动端可用性。  


如果觉得项目有帮助，欢迎Star⭐️支持！如有任何问题，我们随时欢迎您的反馈与建议！
