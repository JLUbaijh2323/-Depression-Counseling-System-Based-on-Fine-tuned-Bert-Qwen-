import os
import logging
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
import torch
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
import numpy as np
import matplotlib.pyplot as plt

# å¢å¼ºæ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("training_log.txt", mode='w', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger()

# æ•°æ®å‡†å¤‡ï¼ˆä¿®å¤åˆ†å±‚æŠ½æ ·é—®é¢˜ï¼‰
os.makedirs("data", exist_ok=True)
os.makedirs("output", exist_ok=True)

dataset = load_dataset("csv", data_files="train.csv")
split_dataset = dataset["train"].train_test_split(test_size=0.2, seed=42)  # ç§»é™¤stratifyå‚æ•°
dataset = {"train": split_dataset["train"], "test": split_dataset["test"]}

# æ˜¾ç¤ºæ•°æ®åˆ†å¸ƒ
logger.info(f"\nè®­ç»ƒé›†æ ·æœ¬æ•°: {len(dataset['train'])}")
logger.info(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(dataset['test'])}")

# åˆ†è¯å™¨åˆå§‹åŒ–
tokenizer = AutoTokenizer.from_pretrained("Geotrend/distilbert-base-zh-cased")

def tokenize_function(examples):
    # éªŒè¯æ ‡ç­¾ï¼ˆä¿æŒä¸å˜ï¼‰
    label_cols = ["S2", "S3", "S9", "è‡ªç„¶ç°è±¡éšå–»", "æœºæ¢°æ•…éšœéšå–»", "ç©ºé—´å‹è¿«éšå–»", "æ˜¯å¦æœ‰æŠ‘éƒ"]
    for col in label_cols:
        invalid = [x for x in examples[col] if x not in {0, 1}]
        if invalid:
            logger.error(f"åˆ— {col} åŒ…å«æ— æ•ˆå€¼: å‰5ä¸ªé”™è¯¯å€¼ {invalid[:5]}...ï¼ˆå…±{len(invalid)}ä¸ªï¼‰")
            raise ValueError(f"æ ‡ç­¾åˆ— {col} å­˜åœ¨é0/1å€¼")

    # å¤„ç†æ–‡æœ¬ï¼ˆä¿æŒä¸å˜ï¼‰
    tokenized = tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=128,
        return_tensors="pt"  # è¿”å›PyTorchå¼ é‡
    )
    
    # ç”Ÿæˆå¤šæ ‡ç­¾å¹¶è½¬æ¢ä¸ºæµ®ç‚¹å‹
    labels = []
    for i in range(len(examples["text"])):
        label_vec = [examples[col][i] for col in label_cols]
        labels.append(label_vec)  # åŸå§‹æ ‡ç­¾æ˜¯0/1çš„æ•´æ•°åˆ—è¡¨
    
    # å…³é”®ä¿®æ”¹ï¼šå°†æ ‡ç­¾è½¬æ¢ä¸ºæµ®ç‚¹å‹å¼ é‡ï¼ˆè§£å†³ç±»å‹ä¸åŒ¹é…ï¼‰
    labels = torch.tensor(labels, dtype=torch.float32)  # æ˜¾å¼è½¬æ¢ä¸ºæµ®ç‚¹å‹
    
    # è®°å½•æ ‡ç­¾åˆ†å¸ƒï¼ˆä¿æŒä¸å˜ï¼‰
    if not hasattr(tokenize_function, 'logged'):
        logger.info(f"æ ·æœ¬æ ‡ç­¾ç¤ºä¾‹: {labels[:3].tolist()}")
        logger.info(f"æ­£æ ·æœ¬åˆ†å¸ƒ: {labels.mean(dim=0).tolist()}")
        tokenize_function.logged = True
    
    # æ³¨æ„ï¼šéœ€è¦å°†å¼ é‡è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä»¥ä¾¿ä¸datasetsåº“å…¼å®¹ï¼ˆåç»­ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºå¼ é‡ï¼‰
    return {**tokenized, "labels": labels.tolist()}  # è¿”å›æµ®ç‚¹å‹åˆ—è¡¨
tokenized_datasets = {
    "train": dataset["train"].map(tokenize_function, batched=True),
    "test": dataset["test"].map(tokenize_function, batched=True)
}

# æ”¹è¿›çš„æ¨¡å‹ï¼ˆæ·»åŠ ç±»åˆ«æƒé‡ï¼‰
class CustomDistilBertForSequenceClassification(AutoModelForSequenceClassification):
    def __init__(self, config):
        super().__init__(config)
        self.dropout = torch.nn.Dropout(0.3)  # è°ƒæ•´dropoutç‡
        
        # è‡ªåŠ¨è®¡ç®—ç±»åˆ«æƒé‡
        all_labels = np.array(tokenized_datasets["train"]["labels"])
        self.class_weights = torch.tensor(
            [(len(all_labels) / (2 * np.sum(all_labels[:, i]))) for i in range(7)],
            dtype=torch.float32
        )
        logger.info(f"\nç±»åˆ«æƒé‡: {self.class_weights.numpy()}")

    def forward(self, input_ids=None, attention_mask=None, labels=None):
        outputs = super().forward(input_ids=input_ids, attention_mask=attention_mask)
        logits = self.dropout(outputs.logits)
        
        if labels is not None:
            loss_fct = torch.nn.BCEWithLogitsLoss(pos_weight=self.class_weights.to(logits.device))
            loss = loss_fct(logits, labels.float())
            return {"loss": loss, "logits": logits}
        return outputs

model = CustomDistilBertForSequenceClassification.from_pretrained(
    "Geotrend/distilbert-base-zh-cased",
    num_labels=7,
    problem_type="multi_label_classification"
)

def compute_metrics(p):
    # è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼ˆä¿æŒåŸå§‹å½¢çŠ¶ï¼‰
    preds = torch.sigmoid(torch.tensor(p.predictions))  # å½¢çŠ¶ [æ ·æœ¬æ•°, 7]
    labels = torch.tensor(p.label_ids)                  # å½¢çŠ¶ [æ ·æœ¬æ•°, 7]
    
    # è°ƒæ•´åˆ†ç±»é˜ˆå€¼ï¼ˆå‘é‡åŒ–è®¡ç®—ï¼Œé¿å…å¾ªç¯ï¼‰
    thresholds = torch.tensor([0.4, 0.4, 0.4, 0.5, 0.5, 0.5, 0.4])  # è½¬æ¢ä¸ºå¼ é‡
    binary_preds = (preds > thresholds).float()  # å½¢çŠ¶ [æ ·æœ¬æ•°, 7]ï¼Œå¸ƒå°”è½¬æµ®ç‚¹
    
    # è®¡ç®—æ ‡ç­¾çº§å‡†ç¡®ç‡ï¼ˆæ¯ä¸ªæ ‡ç­¾ä½ç½®çš„é¢„æµ‹æ­£ç¡®æ¯”ä¾‹ï¼‰
    accuracy = (binary_preds == labels).float().mean().item()  # é€å…ƒç´ æ¯”è¾ƒåæ±‚å¹³å‡
    
    # è®¡ç®—å®å¹³å‡æŒ‡æ ‡ï¼ˆç¡®ä¿è¾“å…¥æ˜¯äºŒç»´æ•°ç»„ï¼‰
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels.numpy(), binary_preds.numpy(), average="macro", zero_division=0
    )
    
    # å„æ ‡ç­¾æŒ‡æ ‡
    label_metrics = {}
    for i, col in enumerate(["S2", "S3", "S9", "è‡ªç„¶ç°è±¡éšå–»", "æœºæ¢°æ•…éšœéšå–»", "ç©ºé—´å‹è¿«éšå–»", "æ˜¯å¦æœ‰æŠ‘éƒ"]):
        p, r, f, _ = precision_recall_fscore_support(
            labels[:, i].numpy(), binary_preds[:, i].numpy(), 
            average="binary", zero_division=0
        )
        label_metrics[f"{col}_precision"] = p
        label_metrics[f"{col}_recall"] = r
    
    # ç¡®ä¿è¿”å›å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦æŒ‡æ ‡
    return {
        "accuracy": accuracy,
        "f1": f1,
        "precision": precision,
        "recall": recall,
        **label_metrics
    }
# ä¼˜åŒ–çš„è®­ç»ƒå‚æ•°
training_args = TrainingArguments(
    output_dir="output/distilbert_final_model",
    num_train_epochs=15,  # å¢åŠ è®­ç»ƒè½®æ¬¡
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,  # å¢å¤§è¯„ä¼°æ‰¹æ¬¡
    learning_rate=2e-5,
    weight_decay=0.01,  # å¢å¼ºæ­£åˆ™åŒ–
    warmup_ratio=0.1,   # æ·»åŠ è®­ç»ƒé¢„çƒ­
    logging_steps=30,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="precision",  # ä»¥ç²¾ç¡®ç‡ä¸ºä¼˜åŒ–ç›®æ ‡
    fp16=True,  # å¯ç”¨æ··åˆç²¾åº¦
)

# å¢å¼ºçš„è®­ç»ƒå™¨ï¼ˆä¿®å¤å¯è§†åŒ–æ•°æ®æ”¶é›†ï¼‰
class CustomTrainer(Trainer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.metrics_history = {
            'train_loss': [],
            'eval_loss': [],
            'precision': [],
            'recall': [],
            'f1': []
        }
    
    def on_log(self, logs, **kwargs):
        if "loss" in logs:
            self.metrics_history['train_loss'].append(logs["loss"])
    
    def on_epoch_end(self, args, state, control, **kwargs):
        super().on_epoch_end(args, state, control, **kwargs)
        eval_metrics = self.evaluate()
        
        # è®°å½•æŒ‡æ ‡
        for k in ['eval_loss', 'precision', 'recall', 'f1']:
            self.metrics_history[k].append(eval_metrics[k])
        
        # è¯¦ç»†æ—¥å¿—
        logger.info("\n" + "="*50)
        logger.info(f"Epoch {int(state.epoch)} ç»“æœ:")
        logger.info(f"è®­ç»ƒæŸå¤±: {self.metrics_history['train_loss'][-1]:.4f}")
        logger.info(f"éªŒè¯æŸå¤±: {eval_metrics['eval_loss']:.4f}")
        logger.info(f"å‡†ç¡®ç‡: {eval_metrics['accuracy']:.4f}")
        logger.info(f"ç²¾ç¡®ç‡: {eval_metrics['precision']:.4f}")
        logger.info(f"å¬å›ç‡: {eval_metrics['recall']:.4f}")
        logger.info(f"F1åˆ†æ•°: {eval_metrics['f1']:.4f}")
        
        # è¾“å‡ºå…³é”®æŒ‡æ ‡
        for col in ['æ˜¯å¦æœ‰æŠ‘éƒ', 'S2', 'S3']:
            logger.info(f"{col} ç²¾ç¡®ç‡: {eval_metrics[f'{col}_precision']:.4f}")

# è®­ç»ƒ
trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_datasets["train"],
    eval_dataset=tokenized_datasets["test"],
    compute_metrics=compute_metrics,
)

logger.info("ğŸš€ å¼€å§‹è®­ç»ƒï¼")
trainer.train()
logger.info("âœ… è®­ç»ƒå®Œæˆï¼")

# # æœ€ç»ˆè¯„ä¼°ï¼ˆæ·»åŠ è¯¦ç»†æŒ‡æ ‡è¾“å‡ºï¼‰
# final_metrics = trainer.evaluate()
# logger.info("\nğŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æœ:")
# logger.info(f"éªŒè¯æŸå¤±: {final_metrics['eval_loss']:.4f}")
# # logger.info(f"å‡†ç¡®ç‡: {final_metrics['accuracy']:.4f}")
# # logger.info(f"ç²¾ç¡®ç‡: {final_metrics['precision']:.4f}")
# # logger.info(f"å¬å›ç‡: {final_metrics['recall']:.4f}")
# # logger.info(f"F1åˆ†æ•°: {final_metrics['f1']:.4f}")

# logger.info("\nå„æ ‡ç­¾ç²¾ç¡®ç‡:")
# for col in ["S2", "S3", "S9", "æ˜¯å¦æœ‰æŠ‘éƒ"]:
#     logger.info(f"{col}: {final_metrics[f'{col}_precision']:.4f}")

# # ä¿®å¤çš„å¯è§†åŒ–ï¼ˆç¡®ä¿æ­£ç¡®ä¿å­˜ï¼‰
# def plot_metrics(history):
#     plt.figure(figsize=(14, 10))
    
#     # æŸå¤±æ›²çº¿
#     plt.subplot(2, 2, 1)
#     plt.plot(history['train_loss'], label='Train Loss')
#     plt.plot(history['eval_loss'], label='Eval Loss')
#     plt.title('Training and Validation Loss')
#     plt.xlabel('Epoch')
#     plt.ylabel('Loss')
#     plt.legend()
    
#     # ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿
#     plt.subplot(2, 2, 2)
#     plt.plot(history['precision'], label='Precision')
#     plt.plot(history['recall'], label='Recall')
#     plt.title('Precision-Recall Curve')
#     plt.xlabel('Epoch')
#     plt.ylabel('Score')
#     plt.legend()
    
#     # F1æ›²çº¿
#     plt.subplot(2, 2, 3)
#     plt.plot(history['f1'], label='F1 Score')
#     plt.title('F1 Score Trend')
#     plt.xlabel('Epoch')
#     plt.ylabel('F1 Score')
#     plt.legend()
    
#     plt.tight_layout()
#     plt.savefig("training_metrics.png")
#     plt.close()  # ä¿®å¤å›¾åƒä¿å­˜é—®é¢˜

# plot_metrics(trainer.metrics_history)